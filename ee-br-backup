#!/bin/bash

set -e
set -u

r=`tput setaf 1`
g=`tput setaf 2`
l=`tput setaf 4`
m=`tput setaf 5`
x=`tput sgr0`
b=`tput bold`

# All in One Bash Logger | v0.49 | 20171018 | 20171128 | Nk

scriptname=`basename "$0"`                                            # The name of this script
now="$(date +"%Y-%m-%d_%H-%M-%S")"                                    # The current timestamp
logdir="$HOME/logs/$scriptname"                                       # Don't store anything else than logs in here!
logfile="$logdir/$now"                                                # The new logfile
if [[ -t 1 ]]; then interactive=y; else interactive=n; fi             # Determine if this is an interactive shell
mkdir -p $logdir                                                      # Touch the dir
touch $logfile                                                        # Touch the file
if [ -f $logdir/latest-log ]; then rm $logdir/latest-log; fi          # Remove the old latest-log symlink
ln -s $logfile $logdir/latest-log                                     # Recreate the symlink
( cd $logdir && rm `ls -t | awk 'NR>43'` ) 2> /dev/null || true       # Delete all logs older than the newest 42
exec >  >(tee -ia $logfile)                                           # Log stdout to logfile
if [ $interactive = "n" ]; then exec 2> >(tee -ia $logfile >&2); fi   # Log stderr to logfile if non-interactive
echo && echo "Starting $scriptname script on $now..." && echo         # Write heading to logfile

################################################################################

# Don't change these! | No trailing slash!
projname="EasyEngine-Backup-Restore"
sourcedir=/root/$projname
basedir=/root/openspace42
installdir=$basedir/ee-br
backupsdir=$installdir/backups
archivedir=$backupsdir/archive
latestdir=$backupsdir/latest
restoresdir=$installdir/restores
tmpdir=/tmp/ee-br
wwwdir=/var/www

if [[ $EUID -ne 0 ]]
then
	echo "${r}${b}This script must be run as root. Run it as:${x}"
	echo
	echo "${b}sudo bash $installdir/$scriptname${x}"
	echo
        # Send email indicating backup aborted
        echo "${b}Exiting...${x}"
        echo
        exit
fi

if [ ! -f $installdir/config ]
then
	echo "${r}${b} | $installdir/config | file NOT found.${x}"
	echo
	echo "${b}If you've deleted or moved yours by mistake, simply re-run the initial installation.${x}"
	echo
	# Send email indicating backup aborted
        echo "${b}Exiting...${x}"
        echo
        exit
fi

################################################################################



# Source vars from config file

. $installdir/config



# Purge temp and create directories

if [ -d $tmpdir ]
then
	rm -r $tmpdir/
fi

mkdir -p $archivedir
mkdir -p $latestdir
mkdir -p $tmpdir
backupname=$scriptname-$now
tmpbackupdir=$tmpdir/$backupname
mkdir -p $tmpbackupdir



update_storage_info () {

	free_disk_space="$(df -m --output=avail / | xargs | sed -e 's/Avail //g')"
	www_dir_size="$(du -sm /var/www/ | xargs | sed -e "s|${wwwdir}/||g")"
	est_backup_size=$(($www_dir_size * 2))
	local_archive_items="$(ls -1q $archivedir | wc -l)"
	local_archive_size="$(du -sm $archivedir | xargs | sed "s|${archivedir}||g" | xargs)"

}



purge_loop () {

	if [ $local_archive_items -gt $min_local_backups ]
	then

		counter=$(($counter - 1))

		# Prevent infinite loops in case of rm failure

		if [ $counter = 0 ]
		then
			echo "${r}${b}Infinite loop error caught. Exiting...${b}"
			exit
		fi

		if [ $local_archive_items -gt $counter ]
		then
			tailnumber=$(( $counter + 1 ))
			( cd $archivedir && ls -t | tail -n +"$tailnumber" | xargs -d '\n' rm )
		fi

		update_storage_info

	else

		echo "${r}${b}The specified number of minimum backups to keep [$min_local_backups] is too high $errordescr.${x}"
		echo
		echo "${b}Lower this figure in the | config | file or make more space available on this machine.${x}"
		echo
		# Send email indicating backup aborted
		echo "${b}Exiting...${x}"
		echo
		exit

	fi

}




update_storage_info

### Purge backups older than the latest $max_local_backups

local_archive_items="$(ls -1q $archivedir | wc -l)"
if [ $local_archive_items -gt $max_local_backups ]
then
        tailnumber=$(( $max_local_backups + 1 ))
        ( cd $archivedir && ls -t | tail -n +"$tailnumber" | xargs -d '\n' rm )
	update_storage_info
fi

echo "${b}You have $local_archive_items local backups occupying $local_archive_size MB of space.${x}"
echo

if [ $local_archive_size -gt $max_local_storage ]
then

	echo "${r}${b}Local archive size [$local_archive_size MB] LARGER than | max_local_storage | setting [$max_local_storage MB].${x}"
	echo
	echo "${b}Now purging old backups while respecting your specified number of minimum backups to keep...${x}"
	echo
	errordescr="to stay below the | max_local_storage | setting you chose"

	counter=$max_local_backups

	while [ $local_archive_size -gt $max_local_storage ]
	do
		purge_loop
	done

	echo "${g}${b}Local archive size now low enough [$local_archive_size MB] to respect your settings.${x}"
	echo
	echo "${b}Purged all backups older than the most recent | $counter |.${x}"
	echo
	echo "${b}Continuing...${x}"
	echo

fi

if [ $est_backup_size -gt $free_disk_space ]
then

	echo "${r}${b}Estimated backup size [$est_backup_size MB] LARGER than available disk space [$free_disk_space MB].${x}"
	echo
	echo "${b}Now purging old backups while respecting your specified number of minimum backups to keep...${x}"
	echo
	errordescr="to free enough disk space for the next backup"

	counter=$max_local_backups

	while [ $est_backup_size -gt $free_disk_space ]
	do
		purge_loop
	done

	echo "${g}${b}Enoguh free space [$free_disk_space MB] now available for new backup.${x}"
	echo
	echo "${b}Purged all backups older than the most recent | $counter |.${x}"
	echo
	echo "${b}Continuing...${x}"
	echo

fi



echo "${b}Now backing up locally...${x}"
echo



for site in $wwwdir/*
do
	if [ -d "$site" ]
	then
		thissite="$(echo "$site" | sed "s|${wwwdir}/||")"
		echo "${b}*] Now evaluating site | ${g}$thissite${x}${b} | ${x}"
		echo
		thissitedir="$tmpbackupdir/$thissite"
		mkdir -p $thissitedir
		wpconfigfile="$site/wp-config.php"
		if [ -f $wpconfigfile ]
		then
			echo "${b}   Proceeding with ${l}wordpress${x}${b} site backup...${x}"
			echo
			WPDBNAME=`cat $wpconfigfile | grep DB_NAME | cut -d \' -f 4`
			WPDBUSER=`cat $wpconfigfile | grep DB_USER | cut -d \' -f 4`
			WPDBPASS=`cat $wpconfigfile | grep DB_PASSWORD | cut -d \' -f 4`
			/usr/bin/mysqldump -u $WPDBUSER -p$WPDBPASS $WPDBNAME > $thissitedir/mysqldump.sql
			cp $wpconfigfile $thissitedir/wp-config.php
		else
			echo "${b}   Proceeding with ${m}NON-wordpress${x}${b} site backup...${x}"
			echo
		fi
		if [ -d $site/htdocs/ ]
		then
			rsync -aAXx $site/htdocs/ $thissitedir/htdocs/
		else
			echo "${r}${b}   No | htdocs | subdirectory found for site | $thissite |. Skipping...${x}"
			echo
		fi
		echo "${b}Finished backup for | $thissite |.${x}"
		echo
	fi
done
echo "${g}${b}Finished backups for all sites.${x}"
echo



echo "${b}Now compressing backup...${x}"
echo

cd $tmpdir
tar cSf - $backupname -P | pv -s $(du -sb $backupname | awk '{print $1}') | bzip2 > $archivedir/$backupname.tar.bz2

echo
echo "${g}${b}Finished compressing backup and stored in | $archivedir/ | ${x}"
echo



if [ $backuptype = "s3" ]
then

        echo "${b}Now backing up to S3...${x}"

        rsync -aAXx $tmpbackupdir/* $latestdir/
        echo

        # Export some ENV variables so you don't have to type anything
        export AWS_ACCESS_KEY_ID=$awsaki
        export AWS_SECRET_ACCESS_KEY=$awssak
        export PASSPHRASE=$backupspw

        # Your GPG key
        #GPG_KEY= # Insert GPG key here if using GPG

        # The S3 destination followed by bucket name
        DEST="s3://$s3endpoint/$s3bucketname/ee-br/latest/"

	duplicitylogdir=/root/logs/$scriptname-duplicity
	duplicitybckplogdir=$duplicitylogdir/backup

        # Set up some variables for logging
        LOGFILE="$duplicitybckplogdir/backup.log"
        DAILYLOGFILE="$duplicitybckplogdir/backup.daily.log"
        FULLBACKLOGFILE="$duplicitybckplogdir/backup.full.log"
        HOST=`hostname`
        DATE=`date +%Y-%m-%d`
        MAILADDR="$adminmail"
        TODAY=$(date +%d%m%Y)

        is_running=$(ps -ef | grep duplicity  | grep python | wc -l)

        if [ ! -d $duplicitybckplogdir ]
        then
                mkdir -p $duplicitybckplogdir
        fi

        if [ ! -f $FULLBACKLOGFILE ]
        then
                touch $FULLBACKLOGFILE
        fi

        if [ $is_running -eq 0 ]
        then
                # Clear the old daily log file
                cat /dev/null > ${DAILYLOGFILE}

                # Trace function for logging, don't change this
                trace () {
                        stamp=`date +%Y-%m-%d_%H:%M:%S`
                        echo "$stamp: $*" >> ${DAILYLOGFILE}
                }

                # How long to keep backups for
                OLDER_THAN="$dup_min_history"

                # The source of your backup
                SOURCE=$latestdir/ # Use / for full system backup [not the case for $scriptname]

                FULL=
                tail -1 ${FULLBACKLOGFILE} | grep ${TODAY} > /dev/null || true
                if [ $? -ne 0 -a $(date +%d) -eq 1 ]
                then
                        FULL=full
                fi;

                trace "Backup for local filesystem started"

                trace "... removing old backups"

                duplicity remove-older-than ${OLDER_THAN} ${DEST} >> ${DAILYLOGFILE} 2>&1 || true

                trace "... backing up filesystem"

                #    duplicity \
                #        ${FULL} \
                #        --encrypt-key=${GPG_KEY} \
                #        --sign-key=${GPG_KEY} \
                #        --include=/var/rsnap-mysql \
                #        --include=/var/www \
                #        --include=/etc \
                #        --exclude=/** \
                #        ${SOURCE} ${DEST} >> ${DAILYLOGFILE} 2>&1

                duplicity ${FULL} ${SOURCE} ${DEST} # Insert --encrypt-key and --sign-key after ${FULL} if using GPG

                trace "Backup for local filesystem complete"
                trace "------------------------------------"

                # Send the daily log file by email
                #cat "$DAILYLOGFILE" | mail -s "Duplicity Backup Log for $HOST - $DATE" $MAILADDR
                #BACKUPSTATUS=`cat "$DAILYLOGFILE" | grep Errors | awk '{ print $2 }'`
                BACKUPSTATUS=`cat "$DAILYLOGFILE" | grep -i error | wc -l`
                if [ "$BACKUPSTATUS" != "0" ]
                then
                        cat "$DAILYLOGFILE" | mail -aFrom:"$scriptname@$HOST" -s "ERROR in $scriptname backup for $HOST on $DATE" $MAILADDR
                elif [ "$FULL" = "full" ]
                then
                        echo "$(date +%d%m%Y_%T) Full Back Done" >> $FULLBACKLOGFILE
                fi

                # Append the daily log file to the main log file
                cat "$DAILYLOGFILE" >> $LOGFILE

                # Reset the ENV variables. Don't need them sitting around
                unset AWS_ACCESS_KEY_ID
                unset AWS_SECRET_ACCESS_KEY
                unset PASSPHRASE

        fi

	### Also upload today's full backup file to S3 if s3_monthly_uploads=y [only if this is NOT a manual run]

	today_day_of_month="$(date +%-d)"

	if [ $today_day_of_month = "1" ] && [ $interactive = "n" ]
	then
		echo "${b}Now copying $archivedir/$backupname.tar.bz2 to S3 as well."
		echo

		encrypt() {
			gpg --output  /$tmpdir/$@ --passphrase "$backupspw" --symmetric -z 9 --require-secmem --cipher-algo AES256 --s2k-cipher-algo AES256 --s2k-digest-algo SHA512 --s2k-mode 3 --s2k-count 65000000 --compress-algo BZIP2 $@
		}

		decrypt() {
			gpg $@
		}

		putS3 () {
			path=$1
			file=$2
			aws_path=$3
			bucket="$s3bucketname"
			date=$(date +"%a, %d %b %Y %T %z")
			acl="x-amz-acl:public-read"
			content_type='application/x-compressed-tar'
			string="PUT\n\n$content_type\n$date\n$acl\n/$bucket$aws_path$file"
			signature=$(echo -en "${string}" | openssl sha1 -hmac "${awssak}" -binary | base64)
			curl -X PUT -T "$path/$file" \
			-H "Host: $bucket.s3.amazonaws.com" \
			-H "Date: $date" \
			-H "Content-Type: $content_type" \
			-H "$acl" \
			-H "Authorization: AWS ${awsaki}:$signature" \
			"https://$bucket.s3.amazonaws.com$aws_path$file"
		}

		( cd $archivedir && encrypt $backupname.tar.bz2 )
		putS3 /$tmpdir/ $backupname.tar.bz2 /ee-br/archive/

	fi

fi

rm -r $tmpbackupdir
rm -r $tmpdir/* 2> /dev/null || true

echo "${g}${b}Backup complete!${x}"
echo
